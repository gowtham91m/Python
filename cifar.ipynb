{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham91m/Python/blob/master/cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7TSiMXNGoY65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, shutil\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers,models,optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "root_dir = '/home/tensor/content/'\n",
        "project_dir = os.path.join(root_dir,'cifar')\n",
        "train_path = os.path.join(project_dir,'train')\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "## data source \n",
        "## https://www.kaggle.com/c/cifar-10/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bN_gC8q-de7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data split using sklearn train test split"
      ]
    },
    {
      "metadata": {
        "id": "-zLSLXihufCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "690b4c7e-dc52-42ff-dc72-5b1db055aa16"
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(project_dir,'trainLabels.csv'))\n",
        "\n",
        "X_train,X_val,y_train,y_val= train_test_split(train_df.id,train_df.label,test_size=0.25\n",
        "                                              ,random_state=5,stratify=train_df.label)\n",
        "\n",
        "train_data = pd.DataFrame({'id':X_train,'label':y_train}).reset_index().drop(['index'],axis=1)\n",
        "val_data = pd.DataFrame({'id':X_val,'label':y_val}).reset_index().drop(['index'],axis=1)\n",
        "\n",
        "datagen=ImageDataGenerator(rescale=1./255.)\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "                                          dataframe=train_data,\n",
        "                                          directory=train_path,\n",
        "                                          x_col=\"id\",\n",
        "                                          y_col=\"label\",\n",
        "                                          has_ext=False,    \n",
        "                                          batch_size=32,\n",
        "                                          seed=42,\n",
        "                                          shuffle=True,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          target_size=(32,32))\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "                                          dataframe=val_data,\n",
        "                                          directory=train_path,\n",
        "                                          x_col=\"id\",\n",
        "                                          y_col=\"label\",\n",
        "                                          has_ext=False,\n",
        "                                          batch_size=32,\n",
        "                                          seed=42,\n",
        "                                          shuffle=True,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          target_size=(32,32))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(32,32,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=5\n",
        ")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 37500 images belonging to 10 classes.\n",
            "Found 12500 images belonging to 10 classes.\n",
            "Epoch 1/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.8775 - acc: 0.3108 - val_loss: 3.0206 - val_acc: 0.0938\n",
            "Epoch 2/5\n",
            "1171/1171 [==============================] - 13s 12ms/step - loss: 1.5783 - acc: 0.4268 - val_loss: 3.4161 - val_acc: 0.0816\n",
            "Epoch 3/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.4440 - acc: 0.4756 - val_loss: 3.7098 - val_acc: 0.0780\n",
            "Epoch 4/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.3488 - acc: 0.5165 - val_loss: 3.9940 - val_acc: 0.0623\n",
            "Epoch 5/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.2728 - acc: 0.5459 - val_loss: 4.2509 - val_acc: 0.0511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee4057e9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "wqpnKCDdJDBB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### data split using subsetting in flow from dataframe"
      ]
    },
    {
      "metadata": {
        "id": "O58yQkOhufJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f8cdc086-b821-412f-e83c-130c3db15011"
      },
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "                                          dataframe=train_df,\n",
        "                                          directory=train_path,\n",
        "                                          x_col=\"id\",\n",
        "                                          y_col=\"label\",\n",
        "                                          has_ext=False,                                      \n",
        "                                          subset=\"training\",\n",
        "                                          batch_size=32,\n",
        "                                          seed=42,\n",
        "                                          shuffle=True,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          target_size=(32,32))\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "                                          dataframe=train_df,\n",
        "                                          directory=train_path,\n",
        "                                          x_col=\"id\",\n",
        "                                          y_col=\"label\",\n",
        "                                          has_ext=False,\n",
        "                                          subset=\"validation\",\n",
        "                                          batch_size=32,\n",
        "                                          seed=42,\n",
        "                                          shuffle=True,\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          target_size=(32,32))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(32,32,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=5\n",
        ")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 37500 images belonging to 10 classes.\n",
            "Found 12500 images belonging to 10 classes.\n",
            "Epoch 1/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.8620 - acc: 0.3140 - val_loss: 1.6039 - val_acc: 0.4213\n",
            "Epoch 2/5\n",
            "1171/1171 [==============================] - 13s 11ms/step - loss: 1.5708 - acc: 0.4257 - val_loss: 1.4356 - val_acc: 0.4827\n",
            "Epoch 3/5\n",
            "1171/1171 [==============================] - 14s 12ms/step - loss: 1.4251 - acc: 0.4853 - val_loss: 1.3136 - val_acc: 0.5383\n",
            "Epoch 4/5\n",
            "1171/1171 [==============================] - 13s 11ms/step - loss: 1.3309 - acc: 0.5228 - val_loss: 1.2447 - val_acc: 0.5626\n",
            "Epoch 5/5\n",
            "1171/1171 [==============================] - 13s 12ms/step - loss: 1.2548 - acc: 0.5549 - val_loss: 1.1719 - val_acc: 0.5872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee9ed18f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}